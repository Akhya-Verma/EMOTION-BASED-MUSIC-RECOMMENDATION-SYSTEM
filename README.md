# Emotion-Based Music Recommendation System ğŸ¶

This project recommends music based on real-time facial emotion detection using **DeepFace** and the **YouTube API**.  
It captures the user's face, detects emotions, and fetches relevant songs from YouTube accordingly.

---

## ğŸš€ Features
- Real-time emotion detection using **OpenCV** and **DeepFace**  
- Emotion-to-music mapping (e.g., happy â†’ upbeat songs, sad â†’ emotional songs)  
- Fetches **top YouTube songs** based on detected emotion  
- Simple UI built with **Streamlit**  

---

## ğŸ› ï¸ Tech Stack
- **Python**  
- **OpenCV** â€“ for capturing webcam input  
- **DeepFace** â€“ for emotion recognition  
- **Google API (YouTube Data API v3)** â€“ for fetching music  
- **Streamlit** â€“ for building the web interface  
- **dotenv** â€“ for API key management  

---

## ğŸ“‚ Installation & Setup

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/emotion-music-recommender.git
   cd emotion-music-recommender
2. **Create a virtual environment (recommended)**
   ```bash
   python -m venv venv
   source venv/bin/activate   # On Mac/Linux
   venv\Scripts\activate      # On Windows
3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
4. **Set up YouTube API Key**
- Create a .env file in the project root
- Add your API key:
  ```bash
   YOUTUBE_API_KEY=your_api_key_here
--- 
## â–¶ï¸ Run the Application
    ```bash
    streamlit run app.py



---

## ğŸ¯ How It Works

1. The app captures your facial expression using OpenCV.
2. DeepFace analyzes your face and predicts your current emotion.
3. The emotion is mapped to a specific music query.
4. The YouTube API fetches the top songs based on that query.
5. The songs are displayed in the Streamlit interface.

---


## ğŸ”® Future Enhancements

- Support for multiple languages in song recommendations
- Integration with Spotify API
- Advanced personalization using user history



